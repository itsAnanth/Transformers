{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "450dafda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "A\n",
      "Length of text: 1115394\n"
     ]
    }
   ],
   "source": [
    "with open('../input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print(text[:150])\n",
    "print(f\"Length of text: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8e7fafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Vocabulary size: 65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "n_vocab = len(chars)\n",
    "\n",
    "\n",
    "print(\"\".join(chars))\n",
    "print(f\"Vocabulary size: {n_vocab}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecb8eb5",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "We have a custom tokenizer, its a character level tokenizer for the sake of simplicity\n",
    "\n",
    "Some popular tokenizers includes tiktoken (byte pair encoding), sentencepiece (sub word unit encoding)\n",
    "\n",
    "The above stated tokenizers have very large vocabulary (~50k tokens) but this results in much smaller sequences\n",
    "\n",
    "in our case the char level token has only 65 tokens so the resulting sequence will be a one to one mapping of each character and length of sequence will scale linearly (which is bad)\n",
    "\n",
    "> TODO use one of the popular tokenizers later while implementing to see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5310b22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "char2idx = { ch: i for i, ch in enumerate(chars) }\n",
    "idx2char = { i: ch for i, ch in enumerate(chars) }\n",
    "\n",
    "encode = lambda string: [char2idx[char] for char in string]\n",
    "decode = lambda tensor: \"\".join([idx2char[idx] for idx in tensor])\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd10078",
   "metadata": {},
   "source": [
    "### Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4367bf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])\n",
    "print(decode(data[:100].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2750ad84",
   "metadata": {},
   "source": [
    "### Train - Validate Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f35d7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003854 111540\n"
     ]
    }
   ],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "print(len(train_data), len(val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6943c893",
   "metadata": {},
   "source": [
    "### hyperparameters\n",
    "\n",
    "`block_size`\n",
    "\n",
    "> we train the transformer on the above dataset as chunks, feeding in the entire dataset at once would be too computationally expensive, so we ranomly sample \"chunks\" of sequences from the dataset and train on them. The length of this sampled sequence is determined by block_size\n",
    "\n",
    "`n_vocab`\n",
    "\n",
    "> length of vocabulary, vocabulary is basically the number of unique tokens that our transformer will see and generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9a0ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "seed = 1337\n",
    "batch_size = 4\n",
    "n_embedding = n_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ccdd0b",
   "metadata": {},
   "source": [
    "In one of these sequences, there are multiple examples packed in it. in a sequence of length 8 there are 8 unique training examples\n",
    "\n",
    "as such the `+1` is to accomodate a `y` for the last training sample, since `y` starts at an offset of `+1`\n",
    "\n",
    "### Note\n",
    "\n",
    "> The reason why multiple training samples are taken from a single sequence ranging from `1 - block_size` is not just to make it computationally efficient but to get the transformer used to seeing sequences of length in that range. `block_size` is essentially the `context_length` in transformers. During generation as well, when we keep appending generated tokens and during the next forward pass the transformer only sees the last `block_size` tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abee8ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Ci\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47]) tensor([47, 56, 57, 58,  1, 15, 47, 58])\n",
      "when input in: tensor([18]) the target: 47\n",
      "when input in: tensor([18, 47]) the target: 56\n",
      "when input in: tensor([18, 47, 56]) the target: 57\n",
      "when input in: tensor([18, 47, 56, 57]) the target: 58\n",
      "when input in: tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input in: tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input in: tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input in: tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]\n",
    "\n",
    "print(decode(x.tolist()))\n",
    "print(x, y)\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t + 1]\n",
    "    target = y[t]\n",
    "    \n",
    "    print(f\"when input in: {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70ee9b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs, torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets, torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "----------------------------------------\n",
      "when input is tensor([24]), target is 43\n",
      "when input is tensor([24, 43]), target is 58\n",
      "when input is tensor([24, 43, 58]), target is 5\n",
      "when input is tensor([24, 43, 58,  5]), target is 57\n",
      "when input is tensor([24, 43, 58,  5, 57]), target is 1\n",
      "when input is tensor([24, 43, 58,  5, 57,  1]), target is 46\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46]), target is 43\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46, 43]), target is 39\n",
      "when input is tensor([44]), target is 53\n",
      "when input is tensor([44, 53]), target is 56\n",
      "when input is tensor([44, 53, 56]), target is 1\n",
      "when input is tensor([44, 53, 56,  1]), target is 58\n",
      "when input is tensor([44, 53, 56,  1, 58]), target is 46\n",
      "when input is tensor([44, 53, 56,  1, 58, 46]), target is 39\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39]), target is 58\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39, 58]), target is 1\n",
      "when input is tensor([52]), target is 58\n",
      "when input is tensor([52, 58]), target is 1\n",
      "when input is tensor([52, 58,  1]), target is 58\n",
      "when input is tensor([52, 58,  1, 58]), target is 46\n",
      "when input is tensor([52, 58,  1, 58, 46]), target is 39\n",
      "when input is tensor([52, 58,  1, 58, 46, 39]), target is 58\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58]), target is 1\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58,  1]), target is 46\n",
      "when input is tensor([25]), target is 17\n",
      "when input is tensor([25, 17]), target is 27\n",
      "when input is tensor([25, 17, 27]), target is 10\n",
      "when input is tensor([25, 17, 27, 10]), target is 0\n",
      "when input is tensor([25, 17, 27, 10,  0]), target is 21\n",
      "when input is tensor([25, 17, 27, 10,  0, 21]), target is 1\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1]), target is 54\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1, 54]), target is 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "def get_batch(split):\n",
    "    \n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    x = torch.stack([data[i:i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
    "    \n",
    "    return x, y\n",
    "    \n",
    "xb, yb = get_batch('train')\n",
    "print(f\"inputs, {xb.shape}\")\n",
    "print(xb)\n",
    "print(f\"targets, {yb.shape}\")\n",
    "print(yb)\n",
    "\n",
    "print('-' * 40)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context}, target is {target}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570dfca8",
   "metadata": {},
   "source": [
    "### Language Model\n",
    "\n",
    "For the sake of simplicity we use the simplest form of neural network, the bigram language model\n",
    "\n",
    "### Note\n",
    "\n",
    "> idx has a shape of `(B, T)`. batch, time dimensions respectively\n",
    "\n",
    "> output has a shape of `(B, T, C)`. where `C` is the embedding dimension\n",
    "\n",
    "How output becomes that shape is basically, each token idx has an associated `(65, )` dimensional vector in the embedding table, since there are 8 tokens in a sequence (block size), there will be a corresponding embedding vector for each of those tokens. this is done for all sequences in the batch (4 sequence in a batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d45a4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "torch.Size([32, 65]) torch.Size([])\n",
      "tensor([[-1.5101, -0.0948,  1.0927,  ..., -0.6126, -0.6597,  0.7624],\n",
      "        [ 0.3323, -0.0872, -0.7470,  ..., -0.6716, -0.9572, -0.9594],\n",
      "        [ 0.2475, -0.6349, -1.2909,  ...,  1.3064, -0.2256, -1.8305],\n",
      "        ...,\n",
      "        [-2.1910, -0.7574,  1.9656,  ..., -0.3580,  0.8585, -0.6161],\n",
      "        [ 0.5978, -0.0514, -0.0646,  ..., -1.4649, -2.0555,  1.8275],\n",
      "        [-0.6787,  0.8662, -1.6433,  ...,  2.3671, -0.7775, -0.2586]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "class BigramLangugeModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vocab):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.token_embedding_table = nn.Embedding(n_vocab, n_embedding)\n",
    "        \n",
    "    def forward(self, idx, targets):\n",
    "        print(idx.shape)\n",
    "        logits: torch.Tensor = self.token_embedding_table(idx)\n",
    "        \n",
    "        # logits is of shape (B, T, C) however cross entropy loss expects (B, C, T)\n",
    "        \n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B * T, C)\n",
    "        targets = targets.view(B * T)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "m = BigramLangugeModel(n_vocab)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape, loss.shape)\n",
    "\n",
    "print(logits)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc390f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
